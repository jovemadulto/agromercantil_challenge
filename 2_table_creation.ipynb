{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_postgres_database():\n",
    "    \"\"\"\n",
    "    Conecta ao PostgreSQL, verifica se o banco existe e cria se nÃ£o existir.\n",
    "    \"\"\"\n",
    "    # Cria URL de conexÃ£o para o banco 'postgres' (banco padrÃ£o do servidor)\n",
    "    default_url = URL.create(\n",
    "        drivername=\"postgresql+psycopg2\",\n",
    "        username=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME\n",
    "    )\n",
    "\n",
    "    # Conecta ao banco padrÃ£o\n",
    "    try:\n",
    "        print('Conectando em:', default_url)\n",
    "        default_engine = create_engine(default_url, isolation_level=\"AUTOCOMMIT\")\n",
    "        with default_engine.connect() as conn:\n",
    "            # Verifica se o banco jÃ¡ existe\n",
    "            result = conn.execute(\n",
    "                text(\"SELECT 1 FROM pg_database WHERE datname = :dbname\"),\n",
    "                {\"dbname\": DB_NAME}\n",
    "            ).fetchone()\n",
    "\n",
    "            if result:\n",
    "                print(f\"Banco de dados '{DB_NAME}' jÃ¡ existe.\")\n",
    "            else:\n",
    "                # Cria o banco de dados\n",
    "                conn.execute(text(f\"CREATE DATABASE {DB_NAME}\"))\n",
    "                print(f\"Banco de dados '{DB_NAME}' criado com sucesso!\")\n",
    "\n",
    "    except OperationalError as e:\n",
    "        print(\"Erro ao conectar ao PostgreSQL:\", e)\n",
    "        return None\n",
    "\n",
    "    finally:\n",
    "        default_engine.dispose()\n",
    "\n",
    "    # Retorna o engine do banco recÃ©m-criado\n",
    "    db_url = URL.create(\n",
    "        drivername=\"postgresql+psycopg2\",\n",
    "        username=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        database=DB_NAME\n",
    "    )\n",
    "    engine = create_engine(db_url)\n",
    "    print(f\"Conectado ao banco de dados '{DB_NAME}'.\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando em: postgresql+psycopg2://postgres:***@localhost:5433/database_etl\n",
      "Banco de dados 'database_etl' jÃ¡ existe.\n",
      "Conectado ao banco de dados 'database_etl'.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = int(os.getenv(\"DB_PORT\", 5432))\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "engine = create_postgres_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in Path('clean_data').glob('*.csv'):\n",
    "\n",
    "    df = pd.read_csv(file, encoding='cp1252')\n",
    "    df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y')\n",
    "    \n",
    "    if ('sao_paulo' in file.stem) or ('santos' in file.stem):\n",
    "        df['region'] = 'SP'\n",
    "    elif ('irga' in file.stem) or ('rio_grande_sul' in file.stem):\n",
    "        df['region'] = 'RS'\n",
    "    elif ('parana' in file.stem) or ('paranagua' in file.stem):\n",
    "        df['region'] = 'PR'\n",
    "    else:\n",
    "        df['region'] = 'Brasil'\n",
    "\n",
    "    df = df.rename(columns={'data': 'date'})\n",
    "\n",
    "    # Salvar o DataFrame no banco de dados\n",
    "    tabela_destino = file.stem[:60] # Limita o nome da tabela a 60 caracteres\n",
    "    df.to_sql(tabela_destino, engine, if_exists='replace', index=False)\n",
    "\n",
    "    # print(f\"Dados salvos na tabela '{tabela_destino}' com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando `pg_dump --schema-only --dbname=\"postgresql://postgres:q1w2e3@localhost:5433/database_etl\" > dump.sql` para exportar o esquema do banco de dados criado na Ãºltima cÃ©lula, temos um bom ponto inicial para analisar o schema criado e como melhorÃ¡-lo.\n",
    "\n",
    "O arquivo resultante, `dump.sql`, Ã© analisado e a seguinte soluÃ§Ã£o Ã© proposta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao banco database_etl. Verificando tabelas no schema 'public'...\n",
      "\n",
      "ğŸ”§ Processando tabela: acucar_cristal_branco_cepea_esalq_sao_paulo\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'acucar_cristal_branco_cepea_esalq_sao_paulo' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: algodao_pluma_cepea_esalq_8_dias\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'algodao_pluma_cepea_esalq_8_dias' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_acucar_cristal_santos_fob\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_acucar_cristal_santos_fob' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_arroz_casca_cepea_irga_rs\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_arroz_casca_cepea_irga_rs' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_cafe_robusta_cepea_esalq\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_cafe_robusta_cepea_esalq' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_cafe_arabica_cepea_esalq\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_cafe_arabica_cepea_esalq' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_semanal_etanol_anidro_cepea_esalq_sao_paulo\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_semanal_etanol_anidro_cepea_esalq_sao_paulo' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_semanal_etanol_hidratado_outros_fins_cepea_esalq_s\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_semanal_etanol_hidratado_outros_fins_cepea_esalq_s' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_semanal_etanol_hidratado_combustivel_cepea_esalq_s\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_semanal_etanol_hidratado_combustivel_cepea_esalq_s' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_soja_cepea_esalq_parana\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_soja_cepea_esalq_parana' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_soja_cepea_esalq_paranagua\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_soja_cepea_esalq_paranagua' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: preco_medio_trigo_cepea_esalq_parana\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'preco_medio_trigo_cepea_esalq_parana' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: preco_medio_trigo_cepea_esalq_rio_grande_sul\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'preco_medio_trigo_cepea_esalq_rio_grande_sul' atualizada.\n",
      "\n",
      "ğŸ”§ Processando tabela: indicador_milho_esalq_bm_fbovespa\n",
      "ForÃ§ando coluna 'date' para tipo DATE...\n",
      "  âš™ï¸ Criando Ã­ndice em (date)...\n",
      "  âš™ï¸ Criando Ã­ndice composto (region, date)...\n",
      "âœ… Tabela 'indicador_milho_esalq_bm_fbovespa' atualizada.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ConexÃ£o via SQLAlchemy\n",
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "conn = engine.connect()\n",
    "insp = inspect(engine)\n",
    "\n",
    "schema = \"public\"\n",
    "\n",
    "print(f\"Conectado ao banco {DB_NAME}. Verificando tabelas no schema '{schema}'...\\n\")\n",
    "\n",
    "tables = insp.get_table_names(schema=schema)\n",
    "\n",
    "for table in tables:\n",
    "    print(f\"ğŸ”§ Processando tabela: {table}\")\n",
    "\n",
    "    # Verifica se a tabela jÃ¡ possui coluna id\n",
    "    cols = [col[\"name\"] for col in insp.get_columns(table, schema=schema)]\n",
    "    with engine.begin() as trans:\n",
    "        # === Adicionar PK id se nÃ£o existir ===\n",
    "        if \"id\" not in cols:\n",
    "            print(\"Adicionando coluna 'id' como PRIMARY KEY...\")\n",
    "            trans.execute(text(f\"\"\"\n",
    "                ALTER TABLE \"{schema}\".\"{table}\"\n",
    "                ADD COLUMN id BIGINT GENERATED ALWAYS AS IDENTITY PRIMARY KEY;\n",
    "            \"\"\"))\n",
    "\n",
    "        # === Converter colunas double precision â†’ numeric(14,4) ===\n",
    "        for col in insp.get_columns(table, schema=schema):\n",
    "            if col[\"type\"].__class__.__name__ == \"DOUBLE_PRECISION\":\n",
    "                col_name = col[\"name\"]\n",
    "                print(f\"Convertendo coluna '{col_name}' para numeric(14,4)...\")\n",
    "\n",
    "                trans.execute(text(f\"\"\"\n",
    "                    ALTER TABLE \"{schema}\".\"{table}\"\n",
    "                    ALTER COLUMN \"{col_name}\" TYPE numeric(14,4)\n",
    "                    USING \"{col_name}\"::numeric(14,4);\n",
    "                \"\"\"))\n",
    "\n",
    "        # === Converter colunas de data/hora para date ===\n",
    "        for col in insp.get_columns(table, schema=schema):\n",
    "            col_name = col[\"name\"]\n",
    "            col_type = col[\"type\"].__class__.__name__.lower()\n",
    "            if \"timestamp\" in col_type or col_name.lower() == \"date\":\n",
    "                print(f\"ForÃ§ando coluna '{col_name}' para tipo DATE...\")\n",
    "                trans.execute(text(f\"\"\"\n",
    "                    ALTER TABLE \"{schema}\".\"{table}\"\n",
    "                    ALTER COLUMN \"{col_name}\" TYPE date\n",
    "                    USING \"{col_name}\"::date;\n",
    "                \"\"\"))\n",
    "        \n",
    "        # === 4ï¸âƒ£ Criar Ã­ndices ===\n",
    "        # Ãndice em coluna date (se existir)\n",
    "        if \"date\" in cols:\n",
    "            print(\"Criando Ã­ndice em (date)...\")\n",
    "            trans.execute(text(f\"\"\"\n",
    "                DO $$\n",
    "                BEGIN\n",
    "                    IF NOT EXISTS (\n",
    "                        SELECT 1 FROM pg_indexes \n",
    "                        WHERE schemaname = '{schema}' \n",
    "                        AND tablename = '{table}' \n",
    "                        AND indexname = 'idx_{table}_date'\n",
    "                    ) THEN\n",
    "                        EXECUTE 'CREATE INDEX idx_{table}_date ON \"{schema}\".\"{table}\" (date)';\n",
    "                    END IF;\n",
    "                END $$;\n",
    "            \"\"\"))\n",
    "\n",
    "        # Ãndice composto (region, date) se ambas existirem\n",
    "        if \"region\" in cols and \"date\" in cols:\n",
    "            print(\"Criando Ã­ndice composto (region, date)...\")\n",
    "            trans.execute(text(f\"\"\"\n",
    "                DO $$\n",
    "                BEGIN\n",
    "                    IF NOT EXISTS (\n",
    "                        SELECT 1 FROM pg_indexes \n",
    "                        WHERE schemaname = '{schema}' \n",
    "                        AND tablename = '{table}' \n",
    "                        AND indexname = 'idx_{table}_region_date'\n",
    "                    ) THEN\n",
    "                        EXECUTE 'CREATE INDEX idx_{table}_region_date ON \"{schema}\".\"{table}\" (region, date)';\n",
    "                    END IF;\n",
    "                END $$;\n",
    "            \"\"\"))\n",
    "\n",
    "    print(f\"âœ… Tabela '{table}' atualizada.\\n\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro passo para transformar em modelo estrela (star schema), incluindo uma tabela dimensÃ£o `region`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao banco database_etl. Criando tabela de regiÃµes...\n",
      "âœ… Tabela dim.regions criada e populada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: acucar_cristal_branco_cepea_esalq_sao_paulo\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'acucar_cristal_branco_cepea_esalq_sao_paulo' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: algodao_pluma_cepea_esalq_8_dias\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'algodao_pluma_cepea_esalq_8_dias' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_acucar_cristal_santos_fob\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_acucar_cristal_santos_fob' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_arroz_casca_cepea_irga_rs\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_arroz_casca_cepea_irga_rs' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_cafe_robusta_cepea_esalq\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_cafe_robusta_cepea_esalq' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_cafe_arabica_cepea_esalq\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_cafe_arabica_cepea_esalq' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_semanal_etanol_anidro_cepea_esalq_sao_paulo\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_semanal_etanol_anidro_cepea_esalq_sao_paulo' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_semanal_etanol_hidratado_outros_fins_cepea_esalq_s\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_semanal_etanol_hidratado_outros_fins_cepea_esalq_s' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_semanal_etanol_hidratado_combustivel_cepea_esalq_s\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_semanal_etanol_hidratado_combustivel_cepea_esalq_s' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_soja_cepea_esalq_parana\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_soja_cepea_esalq_parana' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_soja_cepea_esalq_paranagua\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_soja_cepea_esalq_paranagua' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: preco_medio_trigo_cepea_esalq_parana\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'preco_medio_trigo_cepea_esalq_parana' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: preco_medio_trigo_cepea_esalq_rio_grande_sul\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'preco_medio_trigo_cepea_esalq_rio_grande_sul' atualizada.\n",
      "\n",
      "ğŸ”§ Atualizando tabela: indicador_milho_esalq_bm_fbovespa\n",
      "  â• Adicionando coluna region_id...\n",
      "  ğŸ”„ Populando region_id com base em dim.regions...\n",
      "  ğŸ”— Criando FOREIGN KEY (region_id)...\n",
      "âœ… Tabela 'indicador_milho_esalq_bm_fbovespa' atualizada.\n",
      "\n",
      "ğŸ Todas as tabelas conectadas Ã  dimensÃ£o regions com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# === CONEXÃƒO ===\n",
    "engine = create_engine(f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "insp = inspect(engine)\n",
    "\n",
    "print(f\"Conectado ao banco {DB_NAME}. Criando tabela de regiÃµes...\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE SCHEMA IF NOT EXISTS dim;\n",
    "\n",
    "        CREATE TABLE IF NOT EXISTS dim.regions (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            code TEXT UNIQUE NOT NULL,\n",
    "            name TEXT\n",
    "        );\n",
    "\n",
    "        CREATE INDEX IF NOT EXISTS idx_regions_code ON dim.regions (code);\n",
    "        CREATE INDEX IF NOT EXISTS idx_regions_name ON dim.regions (name);\n",
    "\n",
    "        INSERT INTO dim.regions (code, name)\n",
    "        VALUES\n",
    "            ('SP', 'SÃ£o Paulo'),\n",
    "            ('RS', 'Rio Grande do Sul'),\n",
    "            ('PR', 'ParanÃ¡'),\n",
    "            ('Brasil', 'Brasil')\n",
    "        ON CONFLICT (code) DO NOTHING;\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"âœ… Tabela dim.regions criada e populada.\\n\")\n",
    "\n",
    "tables = insp.get_table_names(schema=schema)\n",
    "\n",
    "for table in tables:\n",
    "    cols = [col[\"name\"] for col in insp.get_columns(table, schema=schema)]\n",
    "    if \"region\" not in cols:\n",
    "        continue\n",
    "\n",
    "    print(f\"ğŸ”§ Atualizando tabela: {table}\")\n",
    "\n",
    "    with engine.begin() as trans:\n",
    "        # Adicionar coluna region_id\n",
    "        if \"region_id\" not in cols:\n",
    "            print(\"  â• Adicionando coluna region_id...\")\n",
    "            trans.execute(text(f\"\"\"\n",
    "                ALTER TABLE \"{schema}\".\"{table}\"\n",
    "                ADD COLUMN region_id INT;\n",
    "            \"\"\"))\n",
    "\n",
    "        # Preencher region_id com base em dim.regions\n",
    "        print(\"  ğŸ”„ Populando region_id com base em dim.regions...\")\n",
    "        trans.execute(text(f\"\"\"\n",
    "            UPDATE \"{schema}\".\"{table}\" AS f\n",
    "            SET region_id = r.id\n",
    "            FROM dim.regions AS r\n",
    "            WHERE UPPER(f.region) = UPPER(r.code);\n",
    "        \"\"\"))\n",
    "\n",
    "        # Adicionar FK\n",
    "        print(\"  ğŸ”— Criando FOREIGN KEY (region_id)...\")\n",
    "        trans.execute(text(f\"\"\"\n",
    "            DO $$\n",
    "            BEGIN\n",
    "                IF NOT EXISTS (\n",
    "                    SELECT 1 FROM pg_constraint\n",
    "                    WHERE conname = 'fk_{table}_region'\n",
    "                ) THEN\n",
    "                    ALTER TABLE \"{schema}\".\"{table}\"\n",
    "                    ADD CONSTRAINT fk_{table}_region\n",
    "                    FOREIGN KEY (region_id) REFERENCES dim.regions(id);\n",
    "                END IF;\n",
    "            END $$;\n",
    "        \"\"\"))\n",
    "\n",
    "    print(f\"âœ… Tabela '{table}' atualizada.\\n\")\n",
    "\n",
    "print(\"ğŸ Todas as tabelas conectadas Ã  dimensÃ£o regions com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<imgs/database_etl - dim - regions.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaves PrimÃ¡rias (PK) \n",
    "    - `dim.regions.id` (`SERIAL`)\n",
    "        - Esta coluna foi escolhida como chave primÃ¡ria do modelo estrela porque serve como um identificador Ãºnico e imutÃ¡vel para cada regiÃ£o.\n",
    "        - O campo code (SP, RS, PR, Brasil) poderia ser uma PK natural, mas usar uma PK substituta (surrogate key) evita dependÃªncia de valores textuais e simplifica joins e FKs.\n",
    "        - Facilita expansÃ£o futura (ao renomear \"SP\" para \"SÃ£o Paulo\", por exemplo, nÃ£o geraria incompatibilidade entre as FKs).\n",
    "        - Tipo de dado `SERIAL PRIMARY KEY` Ã© uma boa prÃ¡tica em modelos dimensionais em razÃ£o de sua estabilidade e rapidez em lookups.\n",
    "\n",
    "    - `id` nas outras tabelas\n",
    "        - Tipo de dado `BIGINT GENERATED ALWAYS AS IDENTITY`\n",
    "        - Cada registro Ã© um evento Ãºnico no tempo, ou seja, o preÃ§o de um produto em determinada data em um determinado lugar.\n",
    "        - O `id` neste caso Ã© uma Surrogate Key, o que garante que a linha seja Ãºnica mesmo que os outros dados se repitam.\n",
    "        - A sua existÃªncia simplifica inserÃ§Ãµes e atualizaÃ§Ãµes, alÃ©m de permitir a utilizaÃ§Ã£o de `UNIQUE(region_id, date) sem depender de uma Primary Key\n",
    "        - Usar a PK nas tabelas de fato gera simplicidade operacional e performance de Ã­ndices.\n",
    "\n",
    "- Chaves Estrangeiras (FK)\n",
    "    - `region_id` nas tabelas Fato -> dim.regions(id)\n",
    "        - Viabiliza a integridade referencial entre fatos e dimensÃ£o\n",
    "        - Permite consultas analÃ­ticas por regiÃ£o, unificando nomenclaturas e evitando inconsistÃªncias de texto\n",
    "            - (\"sp\", \"sao_paulo\", \"SAO PAULO\"...)\n",
    "        - Facilita agregaÃ§Ãµes\n",
    "        - Agiliza operaÃ§Ãµes de JOIN e os torna mais seguros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agromercantil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
